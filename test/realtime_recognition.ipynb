{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mtcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from mtcnn import MTCNN\n",
    "#only run on google colab\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "from tensorflow.keras import layers, Sequential, Input\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.layers import Dense, Input\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from keras.models import Model, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change image size as needed\n",
    "img_size = 128\n",
    "img_shape = (img_size, img_size, 3)\n",
    "\n",
    "def inceptionV3():\n",
    "\n",
    "  base_model = Sequential()\n",
    "  inputs = Input((img_size, img_size, 3))\n",
    "  base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=img_shape)\n",
    "  x = base_model(inputs)\n",
    "  x = base_model.output\n",
    "  x = layers.GlobalAveragePooling2D()(x)\n",
    "  x = layers.Dense(512, activation='relu')(x)\n",
    "  predictions = Dense(34, activation='softmax')(x)\n",
    "  model = Model(inputs=base_model.input, outputs=predictions)\n",
    "  return model\n",
    "\n",
    "new_model = inceptionV3()\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change as need, according model your name\n",
    "file_name = 'your-model.h5'\n",
    "\n",
    "model_test = new_model\n",
    "base_dir = '/content/drive/MyDrive/your-dir-model'\n",
    "\n",
    "model_test.load_weights(base_dir  + file_name)\n",
    "\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Face Recognition Single Image Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = MTCNN()\n",
    "#change as needed, e.g formate file (jpg, jpeg, png)\n",
    "test_image = '/content/drive/MyDrive/your-test-image'\n",
    "\n",
    "image = cv2.imread(test_image, cv2.COLOR_BGR2RGB)\n",
    "faces = detector.detect_faces(image)\n",
    "\n",
    "for result in faces:\n",
    "    x, y, w, h = result['box']\n",
    "    x1, y1 = x + w, y + h\n",
    "    \n",
    "    #extract face ROI, convert from BGR to RGB,\n",
    "    #change image size then processing\n",
    "    face = image[y:y1, x:x1]\n",
    "    face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "    face = cv2.resize(face, (128, 128))\n",
    "    face = img_to_array(face)\n",
    "    face = preprocess_input(face)\n",
    "    face = np.expand_dims(face, axis=0)    \n",
    "\n",
    "    #read face with model\n",
    "    predictions = model_test.predict(face)\n",
    "    score_max = np.argmax(predictions[0])\n",
    "    probabilitas = max(predictions[0] * 100)\n",
    "\n",
    "    #class name, change as needed\n",
    "    celebrity = ['Randeep Hooda', 'Rani Mukerji', 'Ranveer Singh', 'Richa Chadda', 'Riteish Deshmukh', 'Saif Ali Khan', 'Salman Khan', 'Sanjay Dutt', 'Sara Ali Khan', 'Shah Rukh Khan', 'Shahid Kapoor', 'Shilpa Shetty', 'Shraddha Kapoor', 'Shreyas Talpade', 'Shruti Haasan', 'Sidharth Malhotra', 'Sonakshi Sinha', 'Sonam Kapoor', 'Suniel Shetty', 'Sunny Deol', 'Sushant Singh Rajput', 'Taapsee Pannu', 'Tabu', 'Tamannaah Bhatia', 'Tiger Shroff', 'Tusshar Kapoor', 'Uday Chopra', 'Vaani Kapoor', 'Varun Dhawan', 'Vicky Kaushal', 'Vidya Balan', 'Vivek Oberoi', 'Yami Gautam', 'Zareen Khan']\n",
    "    label = celebrity[score_max]\n",
    "    print('Probabilitas: ', probabilitas)\n",
    "    print('Celebrity Prediction: ', label)\n",
    "\n",
    "    #probability of detection results \n",
    "    label_roi = \"{}: {:.2f} %\".format(label, probabilitas)\n",
    "    \n",
    "    #show results with rectangle label\n",
    "    cv2.putText(image, label_roi, (x, y - 10),\n",
    "    cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 255, 0), 2)\n",
    "    cv2.rectangle(image, (x, y), (x1, y1), (0, 255, 0), 2)\n",
    "\n",
    "#show output\n",
    "cv2_imshow(image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Realtime Recognition Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only use on google colab\n",
    "from IPython.display import display, Javascript, Image\n",
    "from google.colab.output import eval_js\n",
    "from base64 import b64decode, b64encode\n",
    "import cv2\n",
    "import numpy as np\n",
    "import PIL\n",
    "import io\n",
    "import html\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to convert the JavaScript object into an OpenCV image\n",
    "def js_to_image(js_reply):\n",
    "  \"\"\"\n",
    "  Params:\n",
    "          js_reply: JavaScript object containing image from webcam\n",
    "  Returns:\n",
    "          img: OpenCV BGR image\n",
    "  \"\"\"\n",
    "  # decode base64 image\n",
    "  image_bytes = b64decode(js_reply.split(',')[1])\n",
    "  # convert bytes to numpy array\n",
    "  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
    "  # decode numpy array into OpenCV BGR image\n",
    "  img = cv2.imdecode(jpg_as_np, flags=1)\n",
    "\n",
    "  return img\n",
    "\n",
    "#function to convert OpenCV Rectangle bounding box image into base64 byte string to be overlayed on video stream\n",
    "def bbox_to_bytes(bbox_array):\n",
    "  \"\"\"\n",
    "  Params:\n",
    "          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n",
    "  Returns:\n",
    "        bytes: Base64 image byte string\n",
    "  \"\"\"\n",
    "  # convert array into PIL image\n",
    "  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n",
    "  iobuf = io.BytesIO()\n",
    "  # format bbox into png for return\n",
    "  bbox_PIL.save(iobuf, format='png')\n",
    "  # format return string\n",
    "  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n",
    "\n",
    "  return bbox_bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#JavaScript to properly create our live video stream using our webcam as input\n",
    "def video_stream():\n",
    "  js = Javascript('''\n",
    "    var video;\n",
    "    var div = null;\n",
    "    var stream;\n",
    "    var captureCanvas;\n",
    "    var imgElement;\n",
    "    var labelElement;\n",
    "    \n",
    "    var pendingResolve = null;\n",
    "    var shutdown = false;\n",
    "    \n",
    "    function removeDom() {\n",
    "       stream.getVideoTracks()[0].stop();\n",
    "       video.remove();\n",
    "       div.remove();\n",
    "       video = null;\n",
    "       div = null;\n",
    "       stream = null;\n",
    "       imgElement = null;\n",
    "       captureCanvas = null;\n",
    "       labelElement = null;\n",
    "    }\n",
    "    \n",
    "    function onAnimationFrame() {\n",
    "      if (!shutdown) {\n",
    "        window.requestAnimationFrame(onAnimationFrame);\n",
    "      }\n",
    "      if (pendingResolve) {\n",
    "        var result = \"\";\n",
    "        if (!shutdown) {\n",
    "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 512, 512);\n",
    "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
    "        }\n",
    "        var lp = pendingResolve;\n",
    "        pendingResolve = null;\n",
    "        lp(result);\n",
    "      }\n",
    "    }\n",
    "    \n",
    "    async function createDom() {\n",
    "      if (div !== null) {\n",
    "        return stream;\n",
    "      }\n",
    "\n",
    "      div = document.createElement('div');\n",
    "      div.style.border = '2px solid black';\n",
    "      div.style.padding = '3px';\n",
    "      div.style.width = '100%';\n",
    "      div.style.maxWidth = '600px';\n",
    "      document.body.appendChild(div);\n",
    "      \n",
    "      const modelOut = document.createElement('div');\n",
    "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
    "      labelElement = document.createElement('span');\n",
    "      labelElement.innerText = 'No data';\n",
    "      labelElement.style.fontWeight = 'bold';\n",
    "      modelOut.appendChild(labelElement);\n",
    "      div.appendChild(modelOut);\n",
    "           \n",
    "      video = document.createElement('video');\n",
    "      video.style.display = 'block';\n",
    "      video.width = div.clientWidth - 6;\n",
    "      video.setAttribute('playsinline', '');\n",
    "      video.onclick = () => { shutdown = true; };\n",
    "      stream = await navigator.mediaDevices.getUserMedia(\n",
    "          {video: { facingMode: \"environment\"}});\n",
    "      div.appendChild(video);\n",
    "\n",
    "      imgElement = document.createElement('img');\n",
    "      imgElement.style.position = 'absolute';\n",
    "      imgElement.style.zIndex = 1;\n",
    "      imgElement.onclick = () => { shutdown = true; };\n",
    "      div.appendChild(imgElement);\n",
    "      \n",
    "      const instruction = document.createElement('div');\n",
    "      instruction.innerHTML = \n",
    "          '<span style=\"color: red; font-weight: bold;\">' +\n",
    "          'When finished, click here or on the video to stop this demo</span>';\n",
    "      div.appendChild(instruction);\n",
    "      instruction.onclick = () => { shutdown = true; };\n",
    "      \n",
    "      video.srcObject = stream;\n",
    "      await video.play();\n",
    "\n",
    "      captureCanvas = document.createElement('canvas');\n",
    "      captureCanvas.width = 512; // video.videoWidth;\n",
    "      captureCanvas.height = 512; // video.videoHeight;\n",
    "      window.requestAnimationFrame(onAnimationFrame);\n",
    "      \n",
    "      return stream;\n",
    "    }\n",
    "    async function stream_frame(label, imgData) {\n",
    "      if (shutdown) {\n",
    "        removeDom();\n",
    "        shutdown = false;\n",
    "        return '';\n",
    "      }\n",
    "\n",
    "      var preCreate = Date.now();\n",
    "      stream = await createDom();\n",
    "      \n",
    "      var preShow = Date.now();\n",
    "      if (label != \"\") {\n",
    "        labelElement.innerHTML = label;\n",
    "      }\n",
    "            \n",
    "      if (imgData != \"\") {\n",
    "        var videoRect = video.getClientRects()[0];\n",
    "        imgElement.style.top = videoRect.top + \"px\";\n",
    "        imgElement.style.left = videoRect.left + \"px\";\n",
    "        imgElement.style.width = videoRect.width + \"px\";\n",
    "        imgElement.style.height = videoRect.height + \"px\";\n",
    "        imgElement.src = imgData;\n",
    "      }\n",
    "      \n",
    "      var preCapture = Date.now();\n",
    "      var result = await new Promise(function(resolve, reject) {\n",
    "        pendingResolve = resolve;\n",
    "      });\n",
    "      shutdown = false;\n",
    "      \n",
    "      return {'create': preShow - preCreate, \n",
    "              'show': preCapture - preShow, \n",
    "              'capture': Date.now() - preCapture,\n",
    "              'img': result};\n",
    "    }\n",
    "    ''')\n",
    "\n",
    "  display(js)\n",
    "  \n",
    "def video_frame(label, bbox):\n",
    "  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start run webcam\n",
    "video_stream()\n",
    "label_html = 'Capturing...'\n",
    "bbox = ''\n",
    "count = 0 \n",
    "detector = MTCNN()\n",
    "\n",
    "while True:\n",
    "    js_reply = video_frame(label_html, bbox)\n",
    "    if not js_reply:\n",
    "        break\n",
    "\n",
    "    #convert Javascript response to opencv image\n",
    "    img = js_to_image(js_reply[\"img\"])\n",
    "    \n",
    "    #create overlay transparent to bounding box\n",
    "    bbox_array = np.zeros([512, 512, 4], dtype=np.uint8)\n",
    "\n",
    "    faces = detector.detect_faces(img)\n",
    "    faces_list = []\n",
    "    preds = []\n",
    "\n",
    "    for result in faces:\n",
    "      x, y, w, h = result['box']\n",
    "      x1, y1 = x + w, y + h\n",
    "      \n",
    "      face = image[y:y1, x:x1]\n",
    "      face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "      face = cv2.resize(face, (128, 128))\n",
    "      face = img_to_array(face)\n",
    "      face = preprocess_input(face)\n",
    "      face = np.expand_dims(face, axis=0)\n",
    "     \n",
    "      faces_list.append(face)\n",
    "      \n",
    "      if len(faces_list) > 0:\n",
    "        preds = model_test.predict(faces_list)\n",
    "    \n",
    "      #start predicition\n",
    "      for pred in preds:\n",
    "        celeb_preds = pred\n",
    "        score_max = np.argmax(celeb_preds[0])\n",
    "        \n",
    "      celebrity = ['Randeep Hooda', 'Rani Mukerji', 'Ranveer Singh', 'Richa Chadda', 'Riteish Deshmukh', 'Saif Ali Khan', 'Salman Khan', 'Sanjay Dutt', 'Sara Ali Khan', 'Shah Rukh Khan', 'Shahid Kapoor', 'Shilpa Shetty', 'Shraddha Kapoor', 'Shreyas Talpade', 'Shruti Haasan', 'Sidharth Malhotra', 'Sonakshi Sinha', 'Sonam Kapoor', 'Suniel Shetty', 'Sunny Deol', 'Sushant Singh Rajput', 'Taapsee Pannu', 'Tabu', 'Tamannaah Bhatia', 'Tiger Shroff', 'Tusshar Kapoor', 'Uday Chopra', 'Vaani Kapoor', 'Varun Dhawan', 'Vicky Kaushal', 'Vidya Balan', 'Vivek Oberoi', 'Yami Gautam', 'Zareen Khan']\n",
    "      label = celebrity[score_max]\n",
    "      probabilitas = max(celeb_preds * 100)\n",
    "\n",
    "\t\t  #probability of detection results \n",
    "      label = \"{}: {:.2f}%\".format(label, probabilitas)\n",
    "\n",
    "      #show results with rectangle label\n",
    "      bbox_array = cv2.putText(bbox_array, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 255, 0), 2)\n",
    "      bbox_array = cv2.rectangle(bbox_array, (x, y), (x1, y1), (0, 255, 0), 2)\n",
    "\n",
    "    bbox_array[:,:,3] = (bbox_array.max(axis=2) > 0 ).astype(int) * 255\n",
    "\n",
    "    #convert box overlay to bytes\n",
    "    bbox_bytes = bbox_to_bytes(bbox_array)\n",
    " \n",
    "    #update bboc to frame, then get overlay\n",
    "    bbox = bbox_bytes"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
